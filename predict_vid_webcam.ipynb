{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e468814",
   "metadata": {},
   "source": [
    "# Load the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d7f5ca6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-13T06:39:58.140983Z",
     "start_time": "2022-03-13T06:39:25.804626Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-_zh9lekq because the default path (/home/macot/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "import os\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pickle\n",
    "import random\n",
    "import gc\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "# tf.get_logger().setLevel('ERROR')\n",
    "# tf.autograph.set_verbosity(2)\n",
    "from tensorflow.keras import models, layers, optimizers, applications\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-perfume",
   "metadata": {},
   "source": [
    "# Use OpenCV to load webcam/video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c61583",
   "metadata": {},
   "source": [
    "## Load the pretrained model\n",
    "\n",
    "The best model was VGG16, and this was used to predict the characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "particular-consumer",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-13T06:35:34.415921Z",
     "start_time": "2022-03-13T06:35:33.912593Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-13 14:35:33.918574: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-03-13 14:35:33.918713: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('vgg16_v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "spectacular-tokyo",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-13T06:35:34.420353Z",
     "start_time": "2022-03-13T06:35:34.417609Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lambda (Lambda)             (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " vgg16 (Functional)          (None, None, None, 512)   14714688  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 19)                38931     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,753,619\n",
      "Trainable params: 14,753,619\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "organizational-acrylic",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-13T06:35:34.425491Z",
     "start_time": "2022-03-13T06:35:34.420990Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'a',\n",
       " 1: 'ba',\n",
       " 2: 'dara',\n",
       " 3: 'ei',\n",
       " 4: 'ga',\n",
       " 5: 'ha',\n",
       " 6: 'ka',\n",
       " 7: 'kuw',\n",
       " 8: 'la',\n",
       " 9: 'ma',\n",
       " 10: 'na',\n",
       " 11: 'nga',\n",
       " 12: 'ou',\n",
       " 13: 'pa',\n",
       " 14: 'sa',\n",
       " 15: 'ta',\n",
       " 16: 'tul',\n",
       " 17: 'wa',\n",
       " 18: 'ya'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['a', 'ba', 'dara', 'ei', 'ga', 'ha', 'ka', 'kuw', 'la',\n",
    "          'ma', 'na', 'nga', 'ou', 'pa', 'sa', 'ta', 'tul', 'wa', 'ya']\n",
    "label_dict = {i: j for i, j in zip(range(19), sorted(labels))}\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3bbf92",
   "metadata": {},
   "source": [
    "# Predict from Video\n",
    "enter the filepath of the video file in the code `cap = cv2.VideoCapture(filepath)` as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1235536a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-13T06:35:22.434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR:0@11.522] global /Users/xperience/actions-runner/_work/opencv-python/opencv-python/opencv/modules/videoio/src/cap.cpp (597) open VIDEOIO(CV_IMAGES): raised OpenCV exception:\n",
      "\n",
      "OpenCV(4.5.5) /Users/xperience/actions-runner/_work/opencv-python/opencv-python/opencv/modules/videoio/src/cap_images.cpp:253: error: (-5:Bad argument) CAP_IMAGES: can't find starting number (in the name of file): demo in function 'icvExtractPattern'\n",
      "\n",
      "\n",
      "2022-03-13 14:35:34.557668: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-03-13 14:35:34.615406: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sa 0.9832792\n",
      "sa 0.9866077\n",
      "sa 0.9811701\n",
      "sa 0.9872661\n",
      "sa 0.9587432\n",
      "sa 0.9334822\n",
      "sa 0.9530434\n",
      "sa 0.9583482\n",
      "sa 0.9683574\n",
      "sa 0.9588049\n",
      "sa 0.94433373\n",
      "sa 0.9463751\n",
      "sa 0.9734914\n",
      "sa 0.98681647\n",
      "sa 0.98800474\n",
      "sa 0.9840882\n",
      "sa 0.975453\n",
      "sa 0.9266179\n",
      "sa 0.9206156\n",
      "sa 0.942889\n",
      "sa 0.9757287\n",
      "sa 0.9601366\n",
      "sa 0.9190487\n",
      "sa 0.8969401\n",
      "sa 0.9805833\n",
      "sa 0.95540184\n",
      "sa 0.9664624\n",
      "sa 0.889827\n",
      "sa 0.84830415\n",
      "sa 0.85565484\n",
      "sa 0.9507069\n",
      "sa 0.99113876\n",
      "sa 0.9891131\n",
      "sa 0.9749289\n",
      "sa 0.89930844\n",
      "sa 0.7138174\n",
      "na 0.40029827\n"
     ]
    }
   ],
   "source": [
    "## input the filename here\n",
    "cap = cv2.VideoCapture('baybayin_2.mov')\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "\n",
    "width = 640\n",
    "height = 480\n",
    "cap.set(3, width)\n",
    "cap.set(4, height)\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "## THIS WAS ADDED TO TRY TO SAVE THE VIDEO\n",
    "writer = cv2.VideoWriter('demo', \n",
    "                         cv2.VideoWriter_fourcc(*'XVID'),25, (width, height))\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        success, imgOriginal = cap.read()\n",
    "        img = cv2.resize(imgOriginal, (64, 64))\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        \n",
    "        # Write the video\n",
    "        writer.write(imgOriginal) ## THIS WAS ADDED TO SAVE THE VID\n",
    "\n",
    "        #predict\n",
    "        predictions = model.predict(img)\n",
    "        pred_label = label_dict[np.argmax(predictions)]\n",
    "        probVal = np.amax(predictions)\n",
    "        \n",
    "        threshold = 0.80\n",
    "        if probVal > threshold:\n",
    "            cv2.putText(img=imgOriginal, text=pred_label + ': ' + str(probVal),\n",
    "                        org=(100, 100), fontFace=cv2.FONT_HERSHEY_COMPLEX,\n",
    "                        fontScale=3, color=(255,255,0), thickness=3)\n",
    "            print(pred_label, probVal)\n",
    "        else:\n",
    "            cv2.putText(img=imgOriginal, text='Unable to predict',\n",
    "                        org=(100, 100), fontFace=cv2.FONT_HERSHEY_COMPLEX,\n",
    "                        fontScale=3, color=(255,255,0), thickness=3)\n",
    "            print(pred_label, probVal)\n",
    "\n",
    "        cv2.imshow('BaybAIyin Predictor', imgOriginal)\n",
    "        \n",
    "        time_now = time.time()\n",
    "        num_seconds = time_now - time_start\n",
    "        if num_seconds > 90:\n",
    "            print('Time is up.')\n",
    "            break\n",
    "\n",
    "    except:\n",
    "        print('Error: Closing camera')\n",
    "        success = False\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "\n",
    "    if (cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "        print('Camera closed by user')\n",
    "        success = False\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "\n",
    "    if not success:\n",
    "        print('Failed to capture image')\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "writer.release() ## THIS WAS ADDED\n",
    "cv2.destroyAllWindows()\n",
    "print('Video End')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb6aea4",
   "metadata": {},
   "source": [
    "# Predict from camera Feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95541bf8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-13T06:35:22.435Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Put 0 to acces your webcam\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "# if not cap.isOpened():\n",
    "#     print(\"Cannot open camera\")\n",
    "#     exit()\n",
    "\n",
    "# width = 640\n",
    "# height = 480\n",
    "# cap.set(3, width)\n",
    "# cap.set(4, height)\n",
    "\n",
    "# time_start = time.time()\n",
    "\n",
    "\n",
    "# while True:\n",
    "#     try:\n",
    "#         success, imgOriginal = cap.read()\n",
    "#         img = cv2.resize(imgOriginal, (64, 64))\n",
    "#         img = np.expand_dims(img, axis=0)\n",
    "\n",
    "#         #predict\n",
    "#         predictions = model.predict(img)\n",
    "#         pred_label = label_dict[np.argmax(predictions)]\n",
    "#         probVal = np.amax(predictions)\n",
    "        \n",
    "#         threshold = 0.80\n",
    "#         if probVal > threshold:\n",
    "#             cv2.putText(img=imgOriginal, text=pred_label + ': ' + str(probVal),\n",
    "#                         org=(100, 100), fontFace=cv2.FONT_HERSHEY_COMPLEX,\n",
    "#                         fontScale=3, color=(255,255,0), thickness=3)\n",
    "#             print(pred_label, probVal)\n",
    "#         else:\n",
    "#             cv2.putText(img=imgOriginal, text='Unable to predict',\n",
    "#                         org=(100, 100), fontFace=cv2.FONT_HERSHEY_COMPLEX,\n",
    "#                         fontScale=3, color=(255,255,0), thickness=3)\n",
    "#             print(pred_label, probVal)\n",
    "\n",
    "#         cv2.imshow('BaybAIyin Prediction', imgOriginal)\n",
    "        \n",
    "#         time_now = time.time()\n",
    "#         num_seconds = time_now - time_start\n",
    "#         if num_seconds > 90:\n",
    "#             print('Time is up.')\n",
    "#             break\n",
    "\n",
    "#     except:\n",
    "#         print('Error: Closing camera')\n",
    "#         success = False\n",
    "#         cap.release()\n",
    "#         cv2.destroyAllWindows()\n",
    "#         break\n",
    "\n",
    "#     if (cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "#         print('Camera closed by user')\n",
    "#         success = False\n",
    "#         cap.release()\n",
    "#         cv2.destroyAllWindows()\n",
    "#         break\n",
    "\n",
    "#     if not success:\n",
    "#         print('Failed to capture image')\n",
    "#         cap.release()\n",
    "#         cv2.destroyAllWindows()\n",
    "#         break\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n",
    "# print('Camera closed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad6c82f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-13T06:35:22.436Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"320\" height=\"240\" controls>\n",
    "  <source src=\"baybayin2_demo.mp4\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee3094c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:.conda-msds2022-ml3]",
   "language": "python",
   "name": "conda-env-.conda-msds2022-ml3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
